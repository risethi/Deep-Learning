{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ax-ZRh49UI9X"
      },
      "source": [
        "# Assignment 2\n",
        "## Create a Neural Network using PyTorch for FashionMNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCA0L5R8UI9z"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUgrRYFeUI99"
      },
      "source": [
        "\n",
        "\n",
        "# NN with PyTorch\n",
        "\n",
        "PyTorch has two primitives to work with data <https://pytorch.org/docs/stable/data.html>: \n",
        "- ``torch.utils.data.DataLoader`` and \n",
        "- ``torch.utils.data.Dataset``.\n",
        "\n",
        "``Dataset`` stores the samples and their corresponding labels, and ``DataLoader`` wraps an iterable around\n",
        "the ``Dataset``.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RT6_v0sUI-E"
      },
      "source": [
        "### Import the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "3TtPJSrMUI-J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTsh9A06UI-K"
      },
      "source": [
        "PyTorch offers domain-specific libraries such as \n",
        "- `TorchText <https://pytorch.org/text/stable/index.html>`_, \n",
        "- `TorchVision <https://pytorch.org/vision/stable/index.html>`_, and \n",
        "- `TorchAudio <https://pytorch.org/audio/stable/index.html>`_, \n",
        "all of which include datasets. For this tutorial, we  will be using a TorchVision dataset.\n",
        "\n",
        "The ``torchvision.datasets`` module contains ``Dataset`` objects for many real-world vision data like \n",
        "CIFAR, COCO (`full list here <https://pytorch.org/docs/stable/torchvision/datasets.html>`_). In this tutorial, we\n",
        "use the FashionMNIST dataset. Every TorchVision ``Dataset`` includes two arguments: ``transform`` and\n",
        "``target_transform`` to modify the samples and labels respectively.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NDfqvCjUI-M"
      },
      "source": [
        "### Download training data from open datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "iaPkVDzxUI-R"
      },
      "outputs": [],
      "source": [
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpA9aK11UI-U"
      },
      "source": [
        "### Download test data from open datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "TOv3j4lmUI-V"
      },
      "outputs": [],
      "source": [
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAAjqvZAUI-X"
      },
      "source": [
        "We pass the ``Dataset`` as an argument to ``DataLoader``. This wraps an iterable over our dataset, and supports\n",
        "automatic batching, sampling, shuffling and multiprocess data loading. Here we define a batch size of 64, i.e. each element \n",
        "in the dataloader iterable will return a batch of 64 features and labels.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "jt24MfMyUI-Y",
        "outputId": "254e3ef6-38a5-41eb-bf13-895671deab2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([64])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 8\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size, shuffle=True)\n",
        "\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQOv3BEHUI-a"
      },
      "source": [
        "--------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P19OkDMXUI-b"
      },
      "source": [
        "Creating Models\n",
        "------------------\n",
        "To define a neural network in PyTorch, we create a class that inherits \n",
        "from `nn.Module <https://pytorch.org/docs/stable/generated/torch.nn.Module.html>`_. \n",
        "\n",
        "We define the layers of the network in the ``__init__`` function and specify how data will pass through the network in the ``forward`` function. \n",
        "\n",
        "To accelerate operations in the neural network, we move it to the GPU if available.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOk_ZeQGUI-c"
      },
      "source": [
        "### Get cpu or gpu device for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "gc_GP7WsUI-d"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGZsYO3HUI-e"
      },
      "source": [
        "### Define model\n",
        "- Flatten the image\n",
        "- Sequential Layers\n",
        "    - Linear layer\n",
        "    - ReLU layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "lTfA7Hk4UI-e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4rZ50BJUI-f"
      },
      "source": [
        "--------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbJMU0T_UI-g"
      },
      "source": [
        "Optimizing the Model Parameters\n",
        "----------------------------------------\n",
        "To train a model, we need\n",
        "- `loss function` <https://pytorch.org/docs/stable/nn.html#loss-functions>\n",
        "- `optimizer` <https://pytorch.org/docs/stable/optim.html> \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "YIQGUdH_UI-h"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-3\n",
        "batch_size = 64\n",
        "epochs = 5\n",
        "\n",
        "# Initialize the loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hn19246MUI-h"
      },
      "source": [
        "In a single training loop, the model makes predictions on the training dataset (fed to it in batches), and \n",
        "backpropagates the prediction error to adjust the model's parameters. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "8kooQ7hxUI-m"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):        \n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "        \n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Qz2p6C0UI-n"
      },
      "source": [
        "We also check the model's performance against the test dataset to ensure it is learning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "4sf5Zt27UI-n"
      },
      "outputs": [],
      "source": [
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "            \n",
        "    test_loss /= size\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmdleOUhUI-q"
      },
      "source": [
        "The training process is conducted over several iterations (*epochs*). During each epoch, the model learns \n",
        "parameters to make better predictions. We print the model's accuracy and loss at each epoch; we'd like to see the\n",
        "accuracy increase and the loss decrease with every epoch.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQyXN059UI-r",
        "outputId": "28f16f10-0c90-4a2e-a790-8eb528479dae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.304220  [    0/60000]\n",
            "loss: 2.283556  [ 6400/60000]\n",
            "loss: 2.268587  [12800/60000]\n",
            "loss: 2.259439  [19200/60000]\n",
            "loss: 2.244332  [25600/60000]\n",
            "loss: 2.226686  [32000/60000]\n",
            "loss: 2.207050  [38400/60000]\n",
            "loss: 2.205326  [44800/60000]\n",
            "loss: 2.186641  [51200/60000]\n",
            "loss: 2.140089  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 48.7%, Avg loss: 0.033806 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.119968  [    0/60000]\n",
            "loss: 2.146557  [ 6400/60000]\n",
            "loss: 2.122552  [12800/60000]\n",
            "loss: 2.083463  [19200/60000]\n",
            "loss: 2.083522  [25600/60000]\n",
            "loss: 2.067624  [32000/60000]\n",
            "loss: 2.008271  [38400/60000]\n",
            "loss: 1.969115  [44800/60000]\n",
            "loss: 1.904613  [51200/60000]\n",
            "loss: 1.947462  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 55.0%, Avg loss: 0.029941 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.883143  [    0/60000]\n",
            "loss: 1.876971  [ 6400/60000]\n",
            "loss: 1.853162  [12800/60000]\n",
            "loss: 1.804536  [19200/60000]\n",
            "loss: 1.817919  [25600/60000]\n",
            "loss: 1.655993  [32000/60000]\n",
            "loss: 1.823771  [38400/60000]\n",
            "loss: 1.682373  [44800/60000]\n",
            "loss: 1.651858  [51200/60000]\n",
            "loss: 1.580427  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 60.7%, Avg loss: 0.025025 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.507372  [    0/60000]\n",
            "loss: 1.584997  [ 6400/60000]\n",
            "loss: 1.523993  [12800/60000]\n",
            "loss: 1.333771  [19200/60000]\n",
            "loss: 1.425753  [25600/60000]\n",
            "loss: 1.670850  [32000/60000]\n",
            "loss: 1.424996  [38400/60000]\n",
            "loss: 1.473783  [44800/60000]\n",
            "loss: 1.308236  [51200/60000]\n",
            "loss: 1.317951  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 62.7%, Avg loss: 0.021560 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.515757  [    0/60000]\n",
            "loss: 1.337565  [ 6400/60000]\n",
            "loss: 1.235266  [12800/60000]\n",
            "loss: 1.247383  [19200/60000]\n",
            "loss: 1.179468  [25600/60000]\n",
            "loss: 1.364723  [32000/60000]\n",
            "loss: 1.254285  [38400/60000]\n",
            "loss: 1.223465  [44800/60000]\n",
            "loss: 1.207450  [51200/60000]\n",
            "loss: 1.313972  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.2%, Avg loss: 0.019460 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.024656  [    0/60000]\n",
            "loss: 1.122379  [ 6400/60000]\n",
            "loss: 1.358046  [12800/60000]\n",
            "loss: 1.106752  [19200/60000]\n",
            "loss: 1.215976  [25600/60000]\n",
            "loss: 1.345726  [32000/60000]\n",
            "loss: 1.048965  [38400/60000]\n",
            "loss: 1.290473  [44800/60000]\n",
            "loss: 1.141250  [51200/60000]\n",
            "loss: 1.332626  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 65.1%, Avg loss: 0.017998 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.222583  [    0/60000]\n",
            "loss: 1.288942  [ 6400/60000]\n",
            "loss: 1.096158  [12800/60000]\n",
            "loss: 1.213717  [19200/60000]\n",
            "loss: 1.112182  [25600/60000]\n",
            "loss: 1.152286  [32000/60000]\n",
            "loss: 0.958712  [38400/60000]\n",
            "loss: 1.103908  [44800/60000]\n",
            "loss: 1.213677  [51200/60000]\n",
            "loss: 1.389328  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 66.1%, Avg loss: 0.017017 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1.253950  [    0/60000]\n",
            "loss: 1.201756  [ 6400/60000]\n",
            "loss: 1.019892  [12800/60000]\n",
            "loss: 1.186494  [19200/60000]\n",
            "loss: 1.101319  [25600/60000]\n",
            "loss: 0.966712  [32000/60000]\n",
            "loss: 1.077677  [38400/60000]\n",
            "loss: 0.925661  [44800/60000]\n",
            "loss: 0.890642  [51200/60000]\n",
            "loss: 0.946219  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 66.5%, Avg loss: 0.016255 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 1.064235  [    0/60000]\n",
            "loss: 1.259278  [ 6400/60000]\n",
            "loss: 1.039904  [12800/60000]\n",
            "loss: 1.056623  [19200/60000]\n",
            "loss: 0.970575  [25600/60000]\n",
            "loss: 1.071056  [32000/60000]\n",
            "loss: 0.962382  [38400/60000]\n",
            "loss: 0.998761  [44800/60000]\n",
            "loss: 1.170363  [51200/60000]\n",
            "loss: 0.855527  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 67.0%, Avg loss: 0.015692 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.909516  [    0/60000]\n",
            "loss: 0.900921  [ 6400/60000]\n",
            "loss: 1.005687  [12800/60000]\n",
            "loss: 1.040023  [19200/60000]\n",
            "loss: 1.017176  [25600/60000]\n",
            "loss: 0.987257  [32000/60000]\n",
            "loss: 0.889815  [38400/60000]\n",
            "loss: 0.935817  [44800/60000]\n",
            "loss: 1.162008  [51200/60000]\n",
            "loss: 1.110259  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 67.3%, Avg loss: 0.015268 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7z_aiG1UI-s"
      },
      "source": [
        "--------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDTYrAAxUI-u"
      },
      "source": [
        "Saving Models\n",
        "-------------\n",
        "A common way to save a model is to serialize the internal state dictionary (containing the model parameters).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "ea46d17347ae4496aa4b257153994663",
            "136acd11faca4e05ad0d5632bc59fe58",
            "a8aae3a1d3794c99bd5e4df16e35ad69",
            "883169231d0f47f385e6f9c8e005a989",
            "ea59c5cb204b493da913542b9eeedfae",
            "97aebf7098294169be00caa09f84cd85",
            "d9933af9ea6f4b11bab1703cb2f2eba1",
            "23204de1ccf54079ab4137a10e65a15e",
            "7a4ad71d90e84a2ca3600ced95a25316",
            "d2ac254f86e0410696302288668f35fd",
            "d89ad09be039425d861b8879a3378b01"
          ]
        },
        "id": "CL2GQvYGUI-w",
        "outputId": "bb59fd43-006b-4395-d0ea-34b1d1a9a357"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/528M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea46d17347ae4496aa4b257153994663"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "import torch.onnx as onnx\n",
        "import torchvision.models as models\n",
        "\n",
        "model = models.vgg16(pretrained=True)\n",
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VQPokD8UI-y"
      },
      "source": [
        "Loading Models\n",
        "----------------------------\n",
        "\n",
        "The process for loading a model includes re-creating the model structure and loading\n",
        "the state dictionary into it. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "em-QKvQLUI-1",
        "outputId": "cbf647e0-59a5-4840-e264-0b38f317459b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "model = models.vgg16() # we do not specify pretrained=True, i.e. do not load default weights\n",
        "model.load_state_dict(torch.load('model_weights.pth'))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IT5FZx7UI-3"
      },
      "source": [
        "This model can now be used to make predictions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmHnY-bDUI-4",
        "outputId": "4d427d5b-040c-4d22-d6e6-5b203a4f2fb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        }
      ],
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQgI58TIUI-8"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AN70kEOUI-9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "testing",
      "language": "python",
      "name": "testing"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Task2_NN_FashionMNIST_PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ea46d17347ae4496aa4b257153994663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_136acd11faca4e05ad0d5632bc59fe58",
              "IPY_MODEL_a8aae3a1d3794c99bd5e4df16e35ad69",
              "IPY_MODEL_883169231d0f47f385e6f9c8e005a989"
            ],
            "layout": "IPY_MODEL_ea59c5cb204b493da913542b9eeedfae"
          }
        },
        "136acd11faca4e05ad0d5632bc59fe58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97aebf7098294169be00caa09f84cd85",
            "placeholder": "​",
            "style": "IPY_MODEL_d9933af9ea6f4b11bab1703cb2f2eba1",
            "value": "100%"
          }
        },
        "a8aae3a1d3794c99bd5e4df16e35ad69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23204de1ccf54079ab4137a10e65a15e",
            "max": 553433881,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a4ad71d90e84a2ca3600ced95a25316",
            "value": 553433881
          }
        },
        "883169231d0f47f385e6f9c8e005a989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2ac254f86e0410696302288668f35fd",
            "placeholder": "​",
            "style": "IPY_MODEL_d89ad09be039425d861b8879a3378b01",
            "value": " 528M/528M [00:04&lt;00:00, 131MB/s]"
          }
        },
        "ea59c5cb204b493da913542b9eeedfae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97aebf7098294169be00caa09f84cd85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9933af9ea6f4b11bab1703cb2f2eba1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23204de1ccf54079ab4137a10e65a15e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a4ad71d90e84a2ca3600ced95a25316": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2ac254f86e0410696302288668f35fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d89ad09be039425d861b8879a3378b01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}